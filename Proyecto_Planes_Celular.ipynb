{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripcion del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proyecto surge como una solución práctica a un desafío actual de Megaline, una compañía de telecomunicaciones. Con el avance constante en los servicios móviles, Megaline se ha dado cuenta de que muchos de sus clientes todavía utilizan planes antiguos. Por ello, el proyecto se centtra en desarrollar un método que nos permita analizar los hábitos de uso de los clientes y, en base a esto, recomendar a los clientes uno de los planes más modernos de la empresa: Smart o Ultra. La idea es hacer uso de los datos disponibles sobre los usuarios para hacer recomendaciones personalizadas que se alineen con sus patrones de consumo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desarrollar un Modelo Predictivo: Crear un modelo que pueda identificar el plan más adecuado para cada cliente, utilizando datos de su comportamiento pasado.\n",
    "\n",
    "Preparación y Análisis de Datos: Examinar y procesar el conjunto de datos proporcionado para asegurar su idoneidad para el modelo.\n",
    "\n",
    "División Estratégica de Datos: Segmentar correctamente los datos en conjuntos de entrenamiento, validación y prueba, garantizando así la efectividad y precisión del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "calls       float64\n",
      "minutes     float64\n",
      "messages    float64\n",
      "mb_used     float64\n",
      "is_ultra      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/users_behavior.csv')\n",
    "print(df.head())\n",
    "print()\n",
    "print(df.info())\n",
    "print()\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ver los datos podemos darnos cuenta que no existen datos nulos en nuestro dataset, pero si podemos ver que los mensajes y llamadas son del tipo float, podria ser conveniente modificarlos a int ya que sus valores son enteros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificacion de tipo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['calls'] = df['calls'].astype(int)\n",
    "df['messages'] = df['messages'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificacion de tipo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calls         int64\n",
      "minutes     float64\n",
      "messages      int64\n",
      "mb_used     float64\n",
      "is_ultra      int64\n",
      "dtype: object\n",
      "\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0     40   311.90        83  19915.42         0\n",
      "1     85   516.75        56  22696.96         0\n",
      "2     77   467.66        86  21060.45         0\n",
      "3    106   745.53        81   8437.39         1\n",
      "4     66   418.74         1  14502.75         0\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busqueda de valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados encontrados en df = 0\n"
     ]
    }
   ],
   "source": [
    "duplicados_df = df.duplicated()\n",
    "print(f\"Duplicados encontrados en df = {duplicados_df.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División de Datos en Conjuntos de Entrenamiento, Validación y Prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']\n",
    "\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(\n",
    "    features, target, test_size=0.40, random_state=12345)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_temp, target_temp, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desarrollo y Evaluación del Modelo de Regresión Logistica\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo de regresión logística en el conjunto de validación: 0.7107309486780715\n",
      "Precisión del modelo de regresión logística en el conjunto de prueba: 0.6842923794712286\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "predictions_valid = model.predict(features_valid)\n",
    "\n",
    "result = accuracy_score(target_valid, predictions_valid)\n",
    "print(\"Precisión del modelo de regresión logística en el conjunto de validación:\", result)\n",
    "\n",
    "predictions_test = model.predict(features_test)\n",
    "\n",
    "result_test = accuracy_score(target_test, predictions_test)\n",
    "print(\"Precisión del modelo de regresión logística en el conjunto de prueba:\", result_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desarrollo y Evaluación del Modelo de Bosque Aleatorio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del mejor modelo en el conjunto de validación: 0.8087091757387247 n_estimators: 40 best_depth: 8\n",
      "Precisión del Modelo de Bosque Aleatorio en el conjunto de prueba: 0.7962674961119751\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range(1, 11):\n",
    "        model = RandomForestClassifier(max_depth=depth, random_state=12345, n_estimators=est)\n",
    "        model.fit(features_train, target_train)\n",
    "        predictions_valid = model.predict(features_valid)\n",
    "        result = accuracy_score(target_valid, predictions_valid)\n",
    "        if result > best_result:\n",
    "            best_model = model\n",
    "            best_result = result\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "\n",
    "print(\"Precisión del mejor modelo en el conjunto de validación:\", best_result, \"n_estimators:\", best_est, \"best_depth:\", best_depth)\n",
    "\n",
    "predictions_test = best_model.predict(features_test)\n",
    "\n",
    "result_test = accuracy_score(target_test, predictions_test)\n",
    "print(\"Precisión del Modelo de Bosque Aleatorio en el conjunto de prueba:\", result_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desarrollo y Evaluación del Modelo de Arbol de decision de regresion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del mejor modelo en el conjunto de validación (max_depth = 3): 0.7853810264385692\n",
      "Precisión del Modelo de Arbol de decision de regresion en el conjunto de prueba: 0.7791601866251944\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, predictions_valid)\n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print(f\"Precisión del mejor modelo en el conjunto de validación (max_depth = {best_depth}): {best_result}\")\n",
    "\n",
    "predictions_test = best_model.predict(features_test)\n",
    "\n",
    "result_test = accuracy_score(target_test, predictions_test)\n",
    "print(\"Precisión del Modelo de Arbol de decision de regresion en el conjunto de prueba:\", result_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación y Selección del Mejor Modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de experimentar con varios modelos, los resultados son claros y bastante reveladores. Iniciamos con el modelo de regresión logística, que nos dio una precisión decente de alrededor del 71.0%, un buen punto de inicio pero no lo suficiente para el objetivo del proyecto. Luego, con el modelo de bosque aleatorio, ajustando los hiperparámetros, conseguimos una precisión del 80.8% con 40 estimadores y una profundidad máxima de 8 del conjunto de validacion, y también mantuvo un alto rendimiento con una precisión del 79.6% en el conjunto de prueba.  Este resultado no solo superó nuestras expectativas, sino que también le gano al modelo de árbol de decisión, que con un max_depth de 3, logró una precisión del 78.5% en el conjunto de validacion y un 77.9% en el conjunto de prueba. \n",
    "\n",
    "El modelo de bosque aleatorio demostro ser el más adecuado para entender y predecir el comportamiento de nuestros usuarios. Con esto, decidimos que el bosque aleatorio con sus parámetros afinados es nuestra mejor apuesta para la implementación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones y Recomendaciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al finalizar este proyecto, hemos obtenido insights valiosos y aprendizajes significativos. Lo más destacado ha sido comprobar la viabilidad de usar el análisis de datos para predecir de forma precisa el plan de telefonía móvil más adecuado para los clientes. Entre los diversos modelos que exploramos, el Bosque Aleatorio, con su  precisión del 80.8%, gano como la herramienta más prometedora.\n",
    "\n",
    "Este hallazgo es relevante, ya que destaca la importancia de adaptar y refinar constantemente las estrategias de análisis de datos para mantenerse al día con las necesidades cambiantes de los clientes. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
